import os
import json
import re
import sqlite3
from typing import Dict, Any, List, Tuple, Optional

from dotenv import load_dotenv
from aiogram import Bot, Dispatcher, F
from aiogram.types import (
    Message,
    CallbackQuery,
    InlineKeyboardMarkup,
    InlineKeyboardButton,
)
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.context import FSMContext

from rapidfuzz import process, fuzz
from openai import OpenAI


# =========================
# CONFIG
# =========================
load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

if not BOT_TOKEN:
    raise RuntimeError("–ù–µ—Ç BOT_TOKEN –≤ .env")
if not DEEPSEEK_API_KEY:
    raise RuntimeError("–ù–µ—Ç DEEPSEEK_API_KEY –≤ .env")

FAQ_SEGMENTED_PATH = "faq_segmented.json"
TERMS_SEGMENTED_PATH = "terms_segmented.json"
DB_PATH = "stats.db"

FAQ_PAGE_SIZE = 5
TERMS_PAGE_SIZE = 8

TOP_K = 10
FUZZY_MIN = 55
LLM_MIN_CONF = 0.55

DEEPSEEK_MODEL = "deepseek-chat"
DEEPSEEK_BASE_URL = "https://api.deepseek.com/v1"


# =========================
# HELPERS
# =========================
def normalize(text: str) -> str:
    text = (text or "").lower().strip()
    text = text.replace("—ë", "–µ")
    text = re.sub(r"\s+", " ", text)
    return text


def load_json(path: str) -> Any:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def safe_int(x: str, default: int = 0) -> int:
    try:
        return int(x)
    except Exception:
        return default


def chunk_page(items: List[Any], page: int, page_size: int) -> Tuple[List[Any], int]:
    total_pages = (len(items) - 1) // page_size + 1 if items else 1
    page = max(0, min(page, total_pages - 1))
    start = page * page_size
    end = start + page_size
    return items[start:end], total_pages


# =========================
# LOAD DATA (SEGMENTED)
# =========================
FAQ_SEG = load_json(FAQ_SEGMENTED_PATH)
TERMS_SEG = load_json(TERMS_SEGMENTED_PATH)

# FAQ: category -> groups -> items
FAQ_CATEGORIES: List[Dict[str, Any]] = FAQ_SEG.get("faq", [])
FAQ_BY_ID: Dict[str, Dict[str, Any]] = {}
FAQ_QUESTIONS_NORM: List[str] = []
FAQ_NORM_TO_ID: Dict[str, str] = {}
FAQ_ANSWERS_NORM: List[str] = []
FAQ_ANSWER_NORM_TO_ID: Dict[str, str] = {}


for cat in FAQ_CATEGORIES:
    for grp in cat.get("groups", []):
        for it in grp.get("items", []):
            qid = it["id"]
            FAQ_BY_ID[qid] = it
            qn = normalize(it.get("q", ""))
            FAQ_QUESTIONS_NORM.append(qn)
            # –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –¥—É–±–ª—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ ‚Äî –æ—Å—Ç–∞–≤–∏–º –ø–µ—Ä–≤—ã–π, —ç—Ç–æ –æ–∫
            FAQ_NORM_TO_ID.setdefault(qn, qid)
# –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã —Ç–æ–∂–µ –¥–æ–±–∞–≤–∏–º –≤ –ø–æ–∏—Å–∫
for qid, it in FAQ_BY_ID.items():
    an = normalize(it.get("a", ""))
    if an:
        FAQ_ANSWERS_NORM.append(an)
        # –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –¥—É–±–ª—å –æ—Ç–≤–µ—Ç–æ–≤ ‚Äî –æ—Å—Ç–∞–≤–∏–º –ø–µ—Ä–≤—ã–π
        FAQ_ANSWER_NORM_TO_ID.setdefault(an, qid)


# TERMS: dict kind -> list[{term, definition}]
TERM_KINDS: List[str] = sorted(list(TERMS_SEG.keys()))
TERMS_BY_KIND: Dict[str, List[Dict[str, str]]] = TERMS_SEG

# –±—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø –ø–æ —Ç–µ—Ä–º–∏–Ω—É
TERM_MAP: Dict[str, str] = {}
for kind, arr in TERMS_BY_KIND.items():
    for t in arr:
        TERM_MAP[normalize(t["term"])] = t["definition"]


# =========================
# DB (TOP)
# =========================
def db() -> sqlite3.Connection:
    conn = sqlite3.connect(DB_PATH)
    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS faq_stats (
            qid TEXT PRIMARY KEY,
            cnt INTEGER NOT NULL DEFAULT 0
        )
        """
    )
    conn.commit()
    return conn


def inc_stat(qid: str) -> None:
    conn = db()
    conn.execute(
        "INSERT INTO faq_stats(qid, cnt) VALUES(?, 1) "
        "ON CONFLICT(qid) DO UPDATE SET cnt = cnt + 1",
        (qid,),
    )
    conn.commit()
    conn.close()


def get_top_ids(limit: int = 10) -> List[str]:
    conn = db()
    cur = conn.execute(
        "SELECT qid FROM faq_stats ORDER BY cnt DESC LIMIT ?",
        (limit,),
    )
    rows = [r[0] for r in cur.fetchall()]
    conn.close()
    return [qid for qid in rows if qid in FAQ_BY_ID]


# =========================
# DeepSeek client
# =========================
ds_client = OpenAI(
    api_key=DEEPSEEK_API_KEY,
    base_url=DEEPSEEK_BASE_URL,
)


def fuzzy_candidates(user_text: str, top_k: int) -> List[Tuple[str, int]]:
    user_norm = normalize(user_text)
    results = process.extract(user_norm, FAQ_QUESTIONS_NORM, scorer=fuzz.WRatio, limit=top_k)
    out: List[Tuple[str, int]] = []
    for match, score, _ in results:
        if score >= FUZZY_MIN:
            out.append((match, int(score)))
    return out




def fuzzy_candidates_all(user_text: str, top_k: int) -> List[str]:
    """–ö–∞–Ω–¥–∏–¥–∞—Ç—ã FAQ –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º + –ø–æ –æ—Ç–≤–µ—Ç–∞–º, —Å—Ä–∞–∑—É —Å–ø–∏—Å–∫–æ–º id."""
    user_norm = normalize(user_text)

    q_hits = process.extract(user_norm, FAQ_QUESTIONS_NORM, scorer=fuzz.WRatio, limit=top_k)
    a_hits = process.extract(user_norm, FAQ_ANSWERS_NORM, scorer=fuzz.WRatio, limit=top_k)

    ids: List[str] = []

    for match, score, _ in q_hits:
        if score >= FUZZY_MIN:
            qid = FAQ_NORM_TO_ID.get(match)
            if qid and qid not in ids:
                ids.append(qid)

    for match, score, _ in a_hits:
        if score >= FUZZY_MIN:
            qid = FAQ_ANSWER_NORM_TO_ID.get(match)
            if qid and qid not in ids:
                ids.append(qid)

    return ids[:10]


def deepseek_answer_from_context(user_text: str, ids: List[str]) -> Dict[str, Any]:
    """–°–æ–±–∏—Ä–∞–µ—Ç –æ—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –ø–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–º –ø—É–Ω–∫—Ç–∞–º –±–∞–∑—ã (grounded)."""
    ctx: List[Dict[str, Any]] = []
    for qid in ids[:8]:
        it = FAQ_BY_ID.get(qid)
        if it:
            ctx.append({"id": qid, "q": it.get("q", ""), "a": it.get("a", "")})

    if not ctx:
        return {
            "answer": None,
            "used_ids": [],
            "confidence": 0.0,
            "need_clarify": True,
            "clarify_question": "–Ø –Ω–µ –Ω–∞—à—ë–ª –≤ –±–∞–∑–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –ø—É–Ω–∫—Ç. –ü–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–∏–º–∏ —Å–ª–æ–≤–∞–º–∏ –∏–ª–∏ –¥–æ–±–∞–≤—å –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ.",
        }

    system = (
        "–¢—ã —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ FAQ-–±–æ—Ç–∞ –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤. "
        "–¢–≤–æ—è –≥–ª–∞–≤–Ω–∞—è –∑–∞–¥–∞—á–∞: –¥–∞—Ç—å —Ç–æ—á–Ω—ã–π –∏ –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –ø–æ —Å–∏—Ç—É–∞—Ü–∏–∏. "
        "–£ —Ç–µ–±—è –µ—Å—Ç—å –ö–û–ù–¢–ï–ö–°–¢ (–ø—É–Ω–∫—Ç—ã –±–∞–∑—ã). "
        "–ü—Ä–∞–≤–∏–ª–∞: "
        "1) –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π. "
        "2) –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç, —Å–∫–∞–∂–∏, —á—Ç–æ –≤ –±–∞–∑–µ –Ω–µ—Ç —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞, –∏ –∑–∞–¥–∞–π 1 —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å. "
        "3) –ï—Å–ª–∏ –ø–æ–¥—Ö–æ–¥—è—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—É–Ω–∫—Ç–æ–≤, –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –æ–±—ä–µ–¥–∏–Ω–∏ –∏—Ö, –Ω–æ –±–µ–∑ –≤–æ–¥—ã. "
        "–í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ JSON –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞."
    )

    user = {
        "user_query": user_text,
        "context": ctx,
        "output_format": {
            "answer": "string|null",
            "used_ids": "array of string",
            "confidence": "number 0..1",
            "need_clarify": "boolean",
            "clarify_question": "string|null",
        },
    }

    resp = ds_client.chat.completions.create(
        model=DEEPSEEK_MODEL,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": json.dumps(user, ensure_ascii=False)},
        ],
        temperature=0.0,
    )

    text = (resp.choices[0].message.content or "").strip()
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        m = re.search(r"\{.*\}", text, flags=re.S)
        if m:
            return json.loads(m.group(0))
        return {
            "answer": None,
            "used_ids": [],
            "confidence": 0.0,
            "need_clarify": True,
            "clarify_question": "–ù–µ —Å–º–æ–≥ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏. –°–ø—Ä–æ—Å–∏ —á—É—Ç—å –ø—Ä–æ—â–µ –∏–ª–∏ –≤—ã–±–µ—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç –∏–∑ –ø–æ–∏—Å–∫–∞.",
        }

def deepseek_pick_id(user_text: str, candidates: List[Tuple[str, int]]) -> Dict[str, Any]:
    cand_payload = []
    for q_norm, score in candidates:
        qid = FAQ_NORM_TO_ID.get(q_norm)
        if qid and qid in FAQ_BY_ID:
            cand_payload.append({"id": qid, "q": FAQ_BY_ID[qid]["q"], "score": score})

    if not cand_payload:
        return {"id": None, "confidence": 0.0, "reason": "no_candidates"}

    system = (
        "–¢—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è FAQ-–±–æ—Ç–∞. "
        "–í—ã–±–µ—Ä–∏ –û–î–ò–ù –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π id –∏–∑ —Å–ø–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤. "
        "–ï—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç, –≤–µ—Ä–Ω–∏ id=null. "
        "–û—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ JSON –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞."
    )

    user = {
        "user_query": user_text,
        "candidates": cand_payload,
        "output_format": {"id": "string|null", "confidence": "number 0..1", "reason": "string"},
        "rules": [
            "–í—ã–±–∏—Ä–∞–π —Ç–æ–ª—å–∫–æ id –∏–∑ candidates",
            "–ï—Å–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–∞–±–æ–µ –∏–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ –ø—Ä–æ —ç—Ç–æ, –≤–µ—Ä–Ω–∏ id=null",
            "confidence 0.9+ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–æ—á—Ç–∏ –∏–¥–µ–∞–ª—å–Ω–æ",
        ],
    }

    resp = ds_client.chat.completions.create(
        model=DEEPSEEK_MODEL,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": json.dumps(user, ensure_ascii=False)},
        ],
        temperature=0.0,
    )

    text = (resp.choices[0].message.content or "").strip()

    try:
        return json.loads(text)
    except json.JSONDecodeError:
        m = re.search(r"\{.*\}", text, flags=re.S)
        if m:
            return json.loads(m.group(0))
        return {"id": None, "confidence": 0.0, "reason": "bad_json"}


# =========================
# FSM
# =========================
class SearchFlow(StatesGroup):
    waiting_query = State()


class TermSearchFlow(StatesGroup):
    waiting_query = State()


class ChoiceFlow(StatesGroup):
    waiting_choice = State()



# =========================
# UI: KEYBOARDS
# =========================
def main_menu_kb() -> InlineKeyboardMarkup:
    return InlineKeyboardMarkup(
        inline_keyboard=[
            [InlineKeyboardButton(text="üìö –í–æ–ø—Ä–æ—Å—ã", callback_data="menu:faq_cats:0")],
            [InlineKeyboardButton(text="üîé –ü–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ", callback_data="menu:search")],
            [InlineKeyboardButton(text="‚≠ê –¢–æ–ø-–≤–æ–ø—Ä–æ—Å—ã", callback_data="menu:top")],
            [InlineKeyboardButton(text="üìñ –¢–µ—Ä–º–∏–Ω—ã", callback_data="menu:term_kinds:0")],
        ]
    )


def nav_row(prev_cb: Optional[str], page: int, total_pages: int, next_cb: Optional[str]) -> List[InlineKeyboardButton]:
    row: List[InlineKeyboardButton] = []
    if prev_cb:
        row.append(InlineKeyboardButton(text="‚¨ÖÔ∏è", callback_data=prev_cb))
    row.append(InlineKeyboardButton(text=f"üìÑ {page+1}/{total_pages}", callback_data="noop"))
    if next_cb:
        row.append(InlineKeyboardButton(text="‚û°Ô∏è", callback_data=next_cb))
    return row


# ---- FAQ categories ----
def faq_categories_kb(page: int) -> InlineKeyboardMarkup:
    items, total_pages = chunk_page(FAQ_CATEGORIES, page, page_size=7)

    kb: List[List[InlineKeyboardButton]] = []
    for idx, cat in enumerate(items):
        cat_index = page * 7 + idx
        title = cat.get("category", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è")
        count = cat.get("count", 0)
        kb.append([InlineKeyboardButton(text=f"{title} ({count})", callback_data=f"faq_cat:{cat_index}:0")])

    prev_cb = f"menu:faq_cats:{page-1}" if page > 0 else None
    next_cb = f"menu:faq_cats:{page+1}" if page < total_pages - 1 else None
    kb.append(nav_row(prev_cb, page, total_pages, next_cb))

    kb.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –í –º–µ–Ω—é", callback_data="menu:home")])
    return InlineKeyboardMarkup(inline_keyboard=kb)


# ---- FAQ groups inside category ----
def faq_groups_kb(cat_index: int, page: int) -> InlineKeyboardMarkup:
    cat = FAQ_CATEGORIES[cat_index]
    groups = cat.get("groups", [])
    items, total_pages = chunk_page(groups, page, page_size=7)

    kb: List[List[InlineKeyboardButton]] = []
    for idx, grp in enumerate(items):
        grp_index = page * 7 + idx
        title = grp.get("title", "–ì—Ä—É–ø–ø–∞")
        count = grp.get("count", 0)
        kb.append([InlineKeyboardButton(text=f"{title} ({count})", callback_data=f"faq_grp:{cat_index}:{grp_index}:0")])

    prev_cb = f"faq_cat:{cat_index}:{page-1}" if page > 0 else None
    next_cb = f"faq_cat:{cat_index}:{page+1}" if page < total_pages - 1 else None
    kb.append(nav_row(prev_cb, page, total_pages, next_cb))

    kb.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –ö –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º", callback_data="menu:faq_cats:0")])
    kb.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –í –º–µ–Ω—é", callback_data="menu:home")])
    return InlineKeyboardMarkup(inline_keyboard=kb)


# ---- Questions inside group (5 per page) ----
def faq_questions_kb(cat_index: int, grp_index: int, page: int) -> InlineKeyboardMarkup:
    grp = FAQ_CATEGORIES[cat_index]["groups"][grp_index]
    q_items = grp.get("items", [])
    items, total_pages = chunk_page(q_items, page, page_size=FAQ_PAGE_SIZE)

    kb: List[List[InlineKeyboardButton]] = []
    for it in items:
        kb.append([InlineKeyboardButton(text=it["q"][:80], callback_data=f"faq_q:{it['id']}")])

    prev_cb = f"faq_grp:{cat_index}:{grp_index}:{page-1}" if page > 0 else None
    next_cb = f"faq_grp:{cat_index}:{grp_index}:{page+1}" if page < total_pages - 1 else None
    kb.append(nav_row(prev_cb, page, total_pages, next_cb))

    kb.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –ö –≥—Ä—É–ø–ø–∞–º", callback_data=f"faq_cat:{cat_index}:0")])
    kb.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –í –º–µ–Ω—é", callback_data="menu:home")])
    return InlineKeyboardMarkup(inline_keyboard=kb)


# ---- Search results (pick question) ----
def search_results_kb(ids: List[str]) -> InlineKeyboardMarkup:
    kb: List[List[InlineKeyboardButton]] = []
    for qid in ids[:10]:
        it = FAQ_BY_ID.get(qid)
        if it:
            kb.append([InlineKeyboardButton(text=it["q"][:80], callback_data=f"faq_q:{qid}")])
    kb.append([InlineKeyboardButton(text="üîé –ù–æ–≤—ã–π –ø–æ–∏—Å–∫", callback_data="menu:search")])
    kb.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –í –º–µ–Ω—é", callback_data="menu:home")])
    return InlineKeyboardMarkup(inline_keyboard=kb)

def format_top_options(ids: List[str], limit: int = 3) -> Tuple[List[str], str]:
    """Return (ids_top, text_block) where text_block is numbered options."""
    ids_top = [str(x) for x in ids[:limit]]
    lines = []
    for i, qid in enumerate(ids_top, 1):
        it = FAQ_BY_ID.get(qid) or {}
        q = (it.get('q') or '').strip()
        if not q:
            q = f"–í–∞—Ä–∏–∞–Ω—Ç {i}"
        lines.append(f"{i}) {q[:120]}")
    return ids_top, "\n".join(lines)



# ---- TOP ----
def top_kb() -> InlineKeyboardMarkup:
    top_ids = get_top_ids(10)
    kb: List[List[InlineKeyboardButton]] = []
    if not top_ids:
        kb.append([InlineKeyboardButton(text="–ü–æ–∫–∞ –ø—É—Å—Ç–æ. –û—Ç–∫—Ä–æ–π –≤–æ–ø—Ä–æ—Å—ã –∏ –ø–æ–∫–ª–∏–∫–∞–π üôÇ", callback_data="noop")])
    else:
        for qid in top_ids:
            it = FAQ_BY_ID[qid]
            kb.append([InlineKeyboardButton(text=it["q"][:80], callback_data=f"faq_q:{qid}")])
    kb.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –í –º–µ–Ω—é", callback_data="menu:home")])
    return InlineKeyboardMarkup(inline_keyboard=kb)


# ---- Terms: kinds ----
def term_kinds_kb(page: int) -> InlineKeyboardMarkup:
    items, total_pages = chunk_page(TERM_KINDS, page, page_size=7)

    kb: List[List[InlineKeyboardButton]] = []
    for idx, kind in enumerate(items):
        kind_index = page * 7 + idx
        kb.append([InlineKeyboardButton(text=f"{kind} ({len(TERMS_BY_KIND[kind])})", callback_data=f"term_kind:{kind_index}:0")])

    prev_cb = f"menu:term_kinds:{page-1}" if page > 0 else None
    next_cb = f"menu:term_kinds:{page+1}" if page < total_pages - 1 else None
    kb.append(nav_row(prev_cb, page, total_pages, next_cb))

    kb.append([InlineKeyboardButton(text="üîé –ü–æ–∏—Å–∫ —Ç–µ—Ä–º–∏–Ω–∞", callback_data="menu:term_search")])
    kb.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –í –º–µ–Ω—é", callback_data="menu:home")])
    return InlineKeyboardMarkup(inline_keyboard=kb)


# ---- Terms: inside kind ----
def term_list_kb(kind_index: int, page: int) -> InlineKeyboardMarkup:
    kind = TERM_KINDS[kind_index]
    items_all = TERMS_BY_KIND[kind]
    items, total_pages = chunk_page(items_all, page, page_size=TERMS_PAGE_SIZE)

    kb: List[List[InlineKeyboardButton]] = []
    for t in items:
        kb.append([InlineKeyboardButton(text=t["term"][:60], callback_data=f"term_show:{kind_index}:{normalize(t['term'])}")])

    prev_cb = f"term_kind:{kind_index}:{page-1}" if page > 0 else None
    next_cb = f"term_kind:{kind_index}:{page+1}" if page < total_pages - 1 else None
    kb.append(nav_row(prev_cb, page, total_pages, next_cb))

    kb.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –ö —Ä–∞–∑–¥–µ–ª–∞–º —Ç–µ—Ä–º–∏–Ω–æ–≤", callback_data="menu:term_kinds:0")])
    kb.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –í –º–µ–Ω—é", callback_data="menu:home")])
    return InlineKeyboardMarkup(inline_keyboard=kb)


# =========================
# HANDLERS
# =========================
async def cmd_start(message: Message, state: FSMContext) -> None:
    await state.clear()
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –ù–∞–ø–∏—à–∏ –≤–æ–ø—Ä–æ—Å –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º. –Ø –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –Ω–∞–π—Ç–∏ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –±–∞–∑–µ."
    )


async def noop(call: CallbackQuery) -> None:
    await call.answer()


# ---- MENU router ----
async def menu_router(call: CallbackQuery, state: FSMContext) -> None:
    parts = call.data.split(":")
    if parts[0] != "menu":
        await call.answer()
        return

    action = parts[1]

    if action == "home":
        await state.clear()
        await call.message.edit_text("–í—ã–±–∏—Ä–∞–π, –∫–∞–∫ –∏—Å–∫–∞—Ç—å –æ—Ç–≤–µ—Ç:", reply_markup=main_menu_kb())
        await call.answer()
        return

    if action == "faq_cats":
        await state.clear()
        page = safe_int(parts[2], 0) if len(parts) > 2 else 0
        await call.message.edit_text("–í—ã–±–µ—Ä–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é:", reply_markup=faq_categories_kb(page))
        await call.answer()
        return

    if action == "search":
        await state.set_state(SearchFlow.waiting_query)
        await call.message.edit_text(
            "–ù–∞–ø–∏—à–∏ –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –±–∞–∑–µ.\n–ú–æ–∂–Ω–æ —Å –æ—à–∏–±–∫–∞–º–∏, –∫–∞–∫ –ø–æ–ª—É—á–∏—Ç—Å—è üôÇ",
            reply_markup=InlineKeyboardMarkup(
                inline_keyboard=[[InlineKeyboardButton(text="‚¨ÖÔ∏è –í –º–µ–Ω—é", callback_data="menu:home")]]
            ),
        )
        await call.answer()
        return

    if action == "top":
        await state.clear()
        await call.message.edit_text("–¢–æ–ø-–≤–æ–ø—Ä–æ—Å—ã:", reply_markup=top_kb())
        await call.answer()
        return

    if action == "term_kinds":
        await state.clear()
        page = safe_int(parts[2], 0) if len(parts) > 2 else 0
        await call.message.edit_text("–†–∞–∑–¥–µ–ª—ã —Ç–µ—Ä–º–∏–Ω–æ–≤:", reply_markup=term_kinds_kb(page))
        await call.answer()
        return

    if action == "term_search":
        await state.set_state(TermSearchFlow.waiting_query)
        await call.message.edit_text(
            "–ù–∞–ø–∏—à–∏ —Ç–µ—Ä–º–∏–Ω –∏–ª–∏ –∫—É—Å–æ–∫ —Å–ª–æ–≤–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: sscc, –∞–¥—Ä–µ—Å, –≥mv):",
            reply_markup=InlineKeyboardMarkup(
                inline_keyboard=[[InlineKeyboardButton(text="‚¨ÖÔ∏è –í –º–µ–Ω—é", callback_data="menu:home")]]
            ),
        )
        await call.answer()
        return

    await call.answer()


# ---- FAQ navigation ----
async def faq_cat_handler(call: CallbackQuery) -> None:
    # faq_cat:<cat_index>:<page>
    _, cat_index_s, page_s = call.data.split(":")
    cat_index = safe_int(cat_index_s, 0)
    page = safe_int(page_s, 0)

    if cat_index < 0 or cat_index >= len(FAQ_CATEGORIES):
        await call.answer("–ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", show_alert=True)
        return

    title = FAQ_CATEGORIES[cat_index].get("category", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è")
    await call.message.edit_text(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {title}\n–í—ã–±–µ—Ä–∏ –≥—Ä—É–ø–ø—É:", reply_markup=faq_groups_kb(cat_index, page))
    await call.answer()


async def faq_group_handler(call: CallbackQuery) -> None:
    # faq_grp:<cat_index>:<grp_index>:<page>
    parts = call.data.split(":")
    cat_index = safe_int(parts[1], 0)
    grp_index = safe_int(parts[2], 0)
    page = safe_int(parts[3], 0)

    if cat_index < 0 or cat_index >= len(FAQ_CATEGORIES):
        await call.answer("–ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", show_alert=True)
        return
    groups = FAQ_CATEGORIES[cat_index].get("groups", [])
    if grp_index < 0 or grp_index >= len(groups):
        await call.answer("–ì—Ä—É–ø–ø–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", show_alert=True)
        return

    gtitle = groups[grp_index].get("title", "–ì—Ä—É–ø–ø–∞")
    await call.message.edit_text(f"–ì—Ä—É–ø–ø–∞: {gtitle}\n–í—ã–±–µ—Ä–∏ –≤–æ–ø—Ä–æ—Å:", reply_markup=faq_questions_kb(cat_index, grp_index, page))
    await call.answer()


async def faq_question_handler(call: CallbackQuery) -> None:
    # faq_q:<id>
    _, qid = call.data.split(":", 1)
    it = FAQ_BY_ID.get(qid)
    if not it:
        await call.answer("–í–æ–ø—Ä–æ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
        return

    inc_stat(qid)
    await call.message.answer(it["a"])
    await call.answer()


# ---- SEARCH ----
async def search_query_handler(message: Message, state: FSMContext) -> None:
    user_text = (message.text or "").strip()
    if not user_text:
        await message.answer("–ù–∞–ø–∏—à–∏ —Ç–µ–∫—Å—Ç–æ–º, —á—Ç–æ –∏—â–µ–º üôÇ")
        return

    # –±—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç —Ç–µ—Ä–º–∏–Ω–æ–º ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –∑–∞–ø—Ä–æ—Å —Ç–µ—Ä–º–∏–Ω–∞
    nt = normalize(user_text)

    best = process.extractOne(nt, list(TERM_MAP.keys()), scorer=fuzz.WRatio)
    if best:
        term_norm, score, _ = best
        if score >= 92:
            await message.answer(f"{term_norm.upper()}: {TERM_MAP[term_norm]}")
            return

    m = re.match(r"^(—á—Ç–æ —Ç–∞–∫–æ–µ|—á—Ç–æ –∑–Ω–∞—á–∏—Ç|—Ä–∞—Å—à–∏—Ñ—Ä—É–π|–æ–ø—Ä–µ–¥–µ–ª–∏)\s+(.+)$", nt)
    if m:
        q = m.group(2).strip()
        best2 = process.extractOne(q, list(TERM_MAP.keys()), scorer=fuzz.WRatio)
        if best2:
            term_norm2, score2, _ = best2
            if score2 >= 80:
                await message.answer(f"{term_norm2.upper()}: {TERM_MAP[term_norm2]}")
                return

    ids = fuzzy_candidates_all(user_text, TOP_K)
    result = deepseek_answer_from_context(user_text, ids)

    ans = result.get("answer")
    conf = float(result.get("confidence", 0.0) or 0.0)
    used_ids = result.get("used_ids") or []

    if ans and conf >= LLM_MIN_CONF:
        if used_ids:
            inc_stat(str(used_ids[0]))
        await message.answer(str(ans))
        await state.clear()
        return

    # –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ —É—Ç–æ—á–Ω—è–ª–∫–∞ ‚Äî —Å–ø—Ä–æ—Å–∏–º, –∏ –ø—Ä–µ–¥–ª–æ–∂–∏–º –¥–æ 3 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    if bool(result.get("need_clarify")):
        clarify = result.get("clarify_question") or "–£—Ç–æ—á–Ω–∏ –≤–æ–ø—Ä–æ—Å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞."
        await message.answer(str(clarify))
        if ids:
            ids_top, opts = format_top_options(ids, limit=3)
            await state.set_state(ChoiceFlow.waiting_choice)
            await state.update_data(choice_ids=ids_top)
            await message.answer("–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –≤—ã–±–µ—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç (1-3):\n" + opts)
        return

    if ids:
        ids_top, opts = format_top_options(ids, limit=3)
        await state.set_state(ChoiceFlow.waiting_choice)
        await state.update_data(choice_ids=ids_top)
        await message.answer("–ü–æ—Ö–æ–∂–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤. –ù–∞–ø–∏—à–∏ –Ω–æ–º–µ—Ä (1-3):\n" + opts)
    else:
        await message.answer("–ü–æ –±–∞–∑–µ –ø–æ–∫–∞ –Ω–µ –ø–æ–ø–∞–ª. –ü–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–∏–º–∏ —Å–ª–æ–≤–∞–º–∏.")


# ---- TERMS ----
async def term_kind_handler(call: CallbackQuery) -> None:
    # term_kind:<kind_index>:<page>
    _, kind_index_s, page_s = call.data.split(":")
    kind_index = safe_int(kind_index_s, 0)
    page = safe_int(page_s, 0)

    if kind_index < 0 or kind_index >= len(TERM_KINDS):
        await call.answer("–†–∞–∑–¥–µ–ª –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
        return

    kind = TERM_KINDS[kind_index]
    await call.message.edit_text(f"–¢–µ—Ä–º–∏–Ω—ã: {kind}", reply_markup=term_list_kb(kind_index, page))
    await call.answer()


async def term_show_handler(call: CallbackQuery) -> None:
    # term_show:<kind_index>:<term_norm>
    parts = call.data.split(":", 2)
    kind_index = safe_int(parts[1], 0)
    term_norm = parts[2] if len(parts) > 2 else ""

    defin = TERM_MAP.get(term_norm)
    if not defin:
        await call.answer("–¢–µ—Ä–º–∏–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
        return

    # –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ + –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–ª–∞–≤—É –Ω–∞ –º–µ—Å—Ç–µ (—á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –¥–∞–ª—å—à–µ –ª–∏—Å—Ç–∞—Ç—å)
    await call.message.answer(f"{term_norm.upper()}: {defin}")
    await call.answer()


async def term_search_handler(message: Message, state: FSMContext) -> None:
    q = normalize(message.text or "")
    if not q:
        await message.answer("–ù–∞–ø–∏—à–∏ —Ç–µ—Ä–º–∏–Ω —Ç–µ–∫—Å—Ç–æ–º üôÇ")
        return

    # –ø—Ä–æ—Å—Ç–∞—è –≤—ã–¥–∞—á–∞ —Ç–æ–ø-10 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ –∏ fuzzy
    matches = []
    for term_norm, defin in TERM_MAP.items():
        if q in term_norm:
            matches.append((term_norm, 100))
    if len(matches) < 10:
        # –¥–æ–±–∏–≤–∞–µ–º fuzzy –ø–æ —Ç–µ—Ä–º–∏–Ω–∞–º
        all_terms = list(TERM_MAP.keys())
        for match, score, _ in process.extract(q, all_terms, scorer=fuzz.WRatio, limit=10):
            matches.append((match, int(score)))

    # —É–Ω–∏–∫–∞–ª–∏–∑–∏—Ä—É–µ–º, —Å–æ—Ä—Ç–∏—Ä—É–µ–º
    uniq: Dict[str, int] = {}
    for t, s in matches:
        uniq[t] = max(uniq.get(t, 0), s)
    best = sorted(uniq.items(), key=lambda x: -x[1])[:10]

    if not best:
        await message.answer("–ù–µ –Ω–∞—à—ë–ª —Ç–µ—Ä–º–∏–Ω. –ü–æ–ø—Ä–æ–±—É–π –ø–æ-–¥—Ä—É–≥–æ–º—É.")
        return

    text_lines = ["–ù–∞—à—ë–ª –≤–æ—Ç —á—Ç–æ:"]
    for t, _ in best[:5]:
        text_lines.append(f"- {t.upper()}: {TERM_MAP[t]}")
    await message.answer("\n".join(text_lines))


# ---- DEFAULT TEXT (optional smart assist) ----
async def default_text_handler(message: Message, state: FSMContext) -> None:
    # –µ—Å–ª–∏ –∂–¥—ë–º –≤—ã–±–æ—Ä –≤–∞—Ä–∏–∞–Ω—Ç–∞ ‚Äî –Ω–µ –≤–º–µ—à–∏–≤–∞–µ–º—Å—è
    st = await state.get_state()
    if st == ChoiceFlow.waiting_choice.state:
        return
    if st in {SearchFlow.waiting_query.state, TermSearchFlow.waiting_query.state}:
        return

    user_text = (message.text or "").strip()
    if not user_text:
        return

    # 1) —Ç–µ—Ä–º–∏–Ω—ã ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –∑–∞–ø—Ä–æ—Å —Ç–µ—Ä–º–∏–Ω–∞
    nt = normalize(user_text)

    best = process.extractOne(nt, list(TERM_MAP.keys()), scorer=fuzz.WRatio)
    if best:
        term_norm, score, _ = best
        if score >= 92:
            await message.answer(f"{term_norm.upper()}: {TERM_MAP[term_norm]}")
            return

    m = re.match(r"^(—á—Ç–æ —Ç–∞–∫–æ–µ|—á—Ç–æ –∑–Ω–∞—á–∏—Ç|—Ä–∞—Å—à–∏—Ñ—Ä—É–π|–æ–ø—Ä–µ–¥–µ–ª–∏)\s+(.+)$", nt)
    if m:
        q = m.group(2).strip()
        best2 = process.extractOne(q, list(TERM_MAP.keys()), scorer=fuzz.WRatio)
        if best2:
            term_norm2, score2, _ = best2
            if score2 >= 80:
                await message.answer(f"{term_norm2.upper()}: {TERM_MAP[term_norm2]}")
                return

    # 2) —É–º–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ –±–∞–∑–µ: –∫–∞–Ω–¥–∏–¥–∞—Ç—ã (–≤–æ–ø—Ä–æ—Å—ã+–æ—Ç–≤–µ—Ç—ã) -> –¥–∏–ø—Å–∏–∫ —Å–æ–±–∏—Ä–∞–µ—Ç –æ—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
    ids = fuzzy_candidates_all(user_text, TOP_K)
    result = deepseek_answer_from_context(user_text, ids)

    ans = result.get("answer")
    conf = float(result.get("confidence", 0.0) or 0.0)
    used_ids = result.get("used_ids") or []

    if ans and conf >= LLM_MIN_CONF:
        if used_ids:
            inc_stat(str(used_ids[0]))
        await message.answer(str(ans))
        return

    if bool(result.get("need_clarify")):
        clarify = result.get("clarify_question") or "–£—Ç–æ—á–Ω–∏ –≤–æ–ø—Ä–æ—Å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞."
        await message.answer(str(clarify))
        if ids:
            ids_top, opts = format_top_options(ids, limit=3)
            await state.set_state(ChoiceFlow.waiting_choice)
            await state.update_data(choice_ids=ids_top)
            await message.answer("–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –≤—ã–±–µ—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç (1-3):\n" + opts)
        return

    if ids:
        ids_top, opts = format_top_options(ids, limit=3)
        await state.set_state(ChoiceFlow.waiting_choice)
        await state.update_data(choice_ids=ids_top)
        await message.answer("–ü–æ—Ö–æ–∂–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤. –ù–∞–ø–∏—à–∏ –Ω–æ–º–µ—Ä (1-3):\n" + opts)
    else:
        await message.answer("–ù–µ –Ω–∞—à—ë–ª —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å —á—É—Ç—å –ø—Ä–æ—â–µ.")


# ---- CHOICE (1..3) ----
async def choice_handler(message: Message, state: FSMContext) -> None:
    st = await state.get_state()
    if st != ChoiceFlow.waiting_choice.state:
        return

    txt = (message.text or "").strip()
    if not txt:
        return

    m = re.match(r"^(?:–≤–∞—Ä–∏–∞–Ω—Ç\s*)?(\d)$", txt.lower())
    if not m:
        await message.answer("–ù–∞–ø–∏—à–∏ –Ω–æ–º–µ—Ä 1, 2 –∏–ª–∏ 3 (–∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å).")
        return

    n = int(m.group(1))
    data = await state.get_data()
    ids = data.get("choice_ids") or []
    if not (1 <= n <= len(ids)):
        await message.answer("–¢–∞–∫–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –Ω–µ—Ç. –ù–∞–ø–∏—à–∏ 1, 2 –∏–ª–∏ 3.")
        return

    qid = str(ids[n - 1])
    it = FAQ_BY_ID.get(qid)
    if not it:
        await message.answer("–ù–µ –Ω–∞—à—ë–ª —ç—Ç–æ—Ç –ø—É–Ω–∫—Ç –≤ –±–∞–∑–µ. –°–ø—Ä–æ—Å–∏ –ø–æ-–¥—Ä—É–≥–æ–º—É.")
        await state.clear()
        return

    inc_stat(qid)
    await message.answer(str(it.get("a") or ""))
    await state.clear()


# =========================
# MAIN
# =========================
def main() -> None:
    conn = db()
    conn.close()

    bot = Bot(token=BOT_TOKEN)
    dp = Dispatcher()

    dp.message.register(cmd_start, F.text.in_({"/start", "/help"}))

    # –≤—ã–±–æ—Ä –≤–∞—Ä–∏–∞–Ω—Ç–∞ (1..3), –µ—Å–ª–∏ –±–æ—Ç –ø—Ä–µ–¥–ª–æ–∂–∏–ª –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç—Ä–∞–∫—Ç–æ–≤–æ–∫
    dp.message.register(choice_handler, ChoiceFlow.waiting_choice, F.text)

    # –æ—Å–Ω–æ–≤–Ω–æ–π —É–º–Ω—ã–π —Ä–µ–∂–∏–º
    dp.message.register(default_text_handler, F.text)


    dp.run_polling(bot)


if __name__ == "__main__":
    main()
